{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9f795dd-9ccd-4bfa-8e56-9966dafd1529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total=11.96 | Cls=0.71 | Seg=0.43 | Reg=1081.92\n",
      "Epoch 2: Total=73.47 | Cls=0.57 | Seg=0.34 | Reg=7255.73\n",
      "Epoch 3: Total=1.25 | Cls=0.55 | Seg=0.31 | Reg=39.34\n",
      "Epoch 4: Total=5.03 | Cls=1.50 | Seg=0.34 | Reg=318.96\n",
      "Epoch 5: Total=57.28 | Cls=0.55 | Seg=0.28 | Reg=5645.73\n",
      "Epoch 6: Total=8.74 | Cls=1.38 | Seg=0.27 | Reg=708.62\n",
      "Epoch 7: Total=9.69 | Cls=0.54 | Seg=0.25 | Reg=890.44\n",
      "Epoch 8: Total=0.90 | Cls=0.45 | Seg=0.24 | Reg=20.85\n",
      "Epoch 9: Total=6.77 | Cls=1.51 | Seg=0.23 | Reg=503.47\n",
      "Epoch 10: Total=2.27 | Cls=2.02 | Seg=0.22 | Reg=2.46\n",
      "Epoch 11: Total=0.80 | Cls=0.49 | Seg=0.22 | Reg=9.22\n",
      "Epoch 12: Total=1.97 | Cls=1.49 | Seg=0.21 | Reg=27.15\n",
      "Epoch 13: Total=6.03 | Cls=0.51 | Seg=0.20 | Reg=532.37\n",
      "Epoch 14: Total=1.19 | Cls=0.46 | Seg=0.18 | Reg=54.07\n",
      "Epoch 15: Total=2.26 | Cls=2.06 | Seg=0.18 | Reg=1.57\n",
      "Epoch 16: Total=3.92 | Cls=1.51 | Seg=0.17 | Reg=223.90\n",
      "Epoch 17: Total=4.26 | Cls=0.49 | Seg=0.21 | Reg=355.96\n",
      "Epoch 18: Total=1.48 | Cls=0.50 | Seg=0.15 | Reg=82.64\n",
      "Epoch 19: Total=2.16 | Cls=1.96 | Seg=0.15 | Reg=5.17\n",
      "Epoch 20: Total=0.61 | Cls=0.44 | Seg=0.15 | Reg=1.99\n",
      "Epoch 21: Total=1.67 | Cls=0.44 | Seg=0.14 | Reg=109.24\n",
      "Epoch 22: Total=41.77 | Cls=0.42 | Seg=0.14 | Reg=4121.93\n",
      "Epoch 23: Total=0.80 | Cls=0.47 | Seg=0.18 | Reg=15.55\n",
      "Epoch 24: Total=51.07 | Cls=0.42 | Seg=0.12 | Reg=5053.40\n",
      "Epoch 25: Total=0.74 | Cls=0.41 | Seg=0.12 | Reg=19.93\n",
      "Epoch 26: Total=0.78 | Cls=0.42 | Seg=0.12 | Reg=24.65\n",
      "Epoch 27: Total=2.36 | Cls=0.42 | Seg=0.12 | Reg=182.46\n",
      "Epoch 28: Total=2.28 | Cls=1.54 | Seg=0.11 | Reg=63.17\n",
      "Epoch 29: Total=2.84 | Cls=2.09 | Seg=0.11 | Reg=63.95\n",
      "Epoch 30: Total=43.59 | Cls=0.50 | Seg=0.10 | Reg=4299.19\n",
      "Epoch 31: Total=3.24 | Cls=0.47 | Seg=0.10 | Reg=266.55\n",
      "Epoch 32: Total=1.33 | Cls=0.44 | Seg=0.10 | Reg=78.38\n",
      "Epoch 33: Total=43.27 | Cls=0.46 | Seg=0.09 | Reg=4272.61\n",
      "Epoch 34: Total=3.18 | Cls=1.95 | Seg=0.11 | Reg=112.39\n",
      "Epoch 35: Total=44.43 | Cls=0.50 | Seg=0.10 | Reg=4383.26\n",
      "Epoch 36: Total=1.50 | Cls=0.46 | Seg=0.09 | Reg=95.69\n",
      "Epoch 37: Total=3.21 | Cls=1.96 | Seg=0.08 | Reg=116.79\n",
      "Epoch 38: Total=1.61 | Cls=1.49 | Seg=0.08 | Reg=3.76\n",
      "Epoch 39: Total=3.69 | Cls=1.86 | Seg=0.08 | Reg=175.41\n",
      "Epoch 40: Total=4.14 | Cls=0.57 | Seg=0.07 | Reg=349.91\n",
      "Epoch 41: Total=1.72 | Cls=1.52 | Seg=0.08 | Reg=11.84\n",
      "Epoch 42: Total=1.88 | Cls=1.36 | Seg=0.07 | Reg=45.08\n",
      "Epoch 43: Total=1.93 | Cls=0.55 | Seg=0.07 | Reg=130.99\n",
      "Epoch 44: Total=3.88 | Cls=2.00 | Seg=0.07 | Reg=180.80\n",
      "Epoch 45: Total=4.71 | Cls=0.49 | Seg=0.06 | Reg=415.05\n",
      "Epoch 46: Total=4.26 | Cls=1.89 | Seg=0.07 | Reg=230.27\n",
      "Epoch 47: Total=1.61 | Cls=1.54 | Seg=0.06 | Reg=0.92\n",
      "Epoch 48: Total=4.90 | Cls=0.52 | Seg=0.07 | Reg=431.45\n",
      "Epoch 49: Total=4.12 | Cls=1.91 | Seg=0.07 | Reg=214.28\n",
      "Epoch 50: Total=1.22 | Cls=0.51 | Seg=0.06 | Reg=65.12\n",
      "Epoch 51: Total=5.27 | Cls=0.46 | Seg=0.05 | Reg=475.62\n",
      "Epoch 52: Total=4.01 | Cls=1.87 | Seg=0.05 | Reg=208.99\n",
      "Epoch 53: Total=3.82 | Cls=1.86 | Seg=0.05 | Reg=190.28\n",
      "Epoch 54: Total=2.04 | Cls=1.43 | Seg=0.06 | Reg=55.27\n",
      "Epoch 55: Total=6.17 | Cls=1.47 | Seg=0.07 | Reg=464.02\n",
      "Epoch 56: Total=2.14 | Cls=1.42 | Seg=0.05 | Reg=66.79\n",
      "Epoch 57: Total=2.59 | Cls=0.49 | Seg=0.05 | Reg=205.07\n",
      "Epoch 58: Total=5.77 | Cls=0.45 | Seg=0.05 | Reg=528.24\n",
      "Epoch 59: Total=1.35 | Cls=0.43 | Seg=0.05 | Reg=87.48\n",
      "Epoch 60: Total=3.13 | Cls=0.41 | Seg=0.05 | Reg=267.48\n",
      "Epoch 61: Total=36.06 | Cls=0.41 | Seg=0.05 | Reg=3560.51\n",
      "Epoch 62: Total=2.80 | Cls=0.43 | Seg=0.05 | Reg=232.03\n",
      "Epoch 63: Total=0.84 | Cls=0.43 | Seg=0.05 | Reg=36.15\n",
      "Epoch 64: Total=4.94 | Cls=1.98 | Seg=0.05 | Reg=291.37\n",
      "Epoch 65: Total=1.57 | Cls=1.51 | Seg=0.04 | Reg=1.48\n",
      "Epoch 66: Total=1.55 | Cls=1.38 | Seg=0.04 | Reg=13.17\n",
      "Epoch 67: Total=4.71 | Cls=1.85 | Seg=0.04 | Reg=282.85\n",
      "Epoch 68: Total=1.31 | Cls=0.48 | Seg=0.05 | Reg=78.03\n",
      "Epoch 69: Total=1.56 | Cls=1.52 | Seg=0.04 | Reg=0.07\n",
      "Epoch 70: Total=23.72 | Cls=0.52 | Seg=0.04 | Reg=2315.89\n",
      "Epoch 71: Total=6.26 | Cls=0.43 | Seg=0.05 | Reg=577.97\n",
      "Epoch 72: Total=6.49 | Cls=0.44 | Seg=0.04 | Reg=601.30\n",
      "Epoch 73: Total=37.87 | Cls=0.41 | Seg=0.04 | Reg=3742.21\n",
      "Epoch 74: Total=6.09 | Cls=0.48 | Seg=0.04 | Reg=556.21\n",
      "Epoch 75: Total=6.30 | Cls=0.42 | Seg=0.03 | Reg=584.31\n",
      "Epoch 76: Total=5.52 | Cls=2.01 | Seg=0.03 | Reg=347.86\n",
      "Epoch 77: Total=3.63 | Cls=0.46 | Seg=0.08 | Reg=309.23\n",
      "Epoch 78: Total=6.57 | Cls=0.43 | Seg=0.04 | Reg=610.59\n",
      "Epoch 79: Total=3.46 | Cls=0.37 | Seg=0.03 | Reg=304.85\n",
      "Epoch 80: Total=35.00 | Cls=0.40 | Seg=0.03 | Reg=3456.69\n",
      "Epoch 81: Total=1.05 | Cls=0.42 | Seg=0.04 | Reg=58.33\n",
      "Epoch 82: Total=1.59 | Cls=1.53 | Seg=0.03 | Reg=3.55\n",
      "Epoch 83: Total=2.81 | Cls=0.46 | Seg=0.04 | Reg=232.00\n",
      "Epoch 84: Total=0.54 | Cls=0.40 | Seg=0.06 | Reg=8.05\n",
      "Epoch 85: Total=5.19 | Cls=2.03 | Seg=0.03 | Reg=313.94\n",
      "Epoch 86: Total=1.65 | Cls=1.61 | Seg=0.03 | Reg=0.25\n",
      "Epoch 87: Total=3.38 | Cls=0.44 | Seg=0.03 | Reg=290.67\n",
      "Epoch 88: Total=1.62 | Cls=1.59 | Seg=0.03 | Reg=0.31\n",
      "Epoch 89: Total=3.39 | Cls=0.47 | Seg=0.03 | Reg=289.02\n",
      "Epoch 90: Total=5.80 | Cls=1.95 | Seg=0.03 | Reg=382.08\n",
      "Epoch 91: Total=1.61 | Cls=1.52 | Seg=0.03 | Reg=6.72\n",
      "Epoch 92: Total=29.82 | Cls=0.44 | Seg=0.03 | Reg=2935.35\n",
      "Epoch 93: Total=6.80 | Cls=0.40 | Seg=0.03 | Reg=636.97\n",
      "Epoch 94: Total=1.62 | Cls=1.52 | Seg=0.03 | Reg=6.58\n",
      "Epoch 95: Total=1.52 | Cls=1.49 | Seg=0.03 | Reg=0.09\n",
      "Epoch 96: Total=0.81 | Cls=0.49 | Seg=0.03 | Reg=28.76\n",
      "Epoch 97: Total=1.68 | Cls=1.46 | Seg=0.02 | Reg=19.37\n",
      "Epoch 98: Total=30.42 | Cls=0.48 | Seg=0.03 | Reg=2990.89\n",
      "Epoch 99: Total=28.33 | Cls=0.45 | Seg=0.03 | Reg=2785.16\n",
      "Epoch 100: Total=5.72 | Cls=2.01 | Seg=0.03 | Reg=368.42\n"
     ]
    }
   ],
   "source": [
    "# Teacher Model: Multi-Task (Classification + Segmentation + Regression with Normalized Output)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_classes=3):\n",
    "        super(TeacherNet, self).__init__()\n",
    "        filters = [64, 128, 256, 512]\n",
    "\n",
    "        self.encoder1 = ConvBlock(in_channels, filters[0])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.encoder2 = ConvBlock(filters[0], filters[1])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.encoder3 = ConvBlock(filters[1], filters[2])\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.encoder4 = ConvBlock(filters[2], filters[3])\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = ConvBlock(filters[3], filters[3])\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters[3], 3)\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(filters[3], filters[2], kernel_size=2, stride=2)\n",
    "        self.decoder1 = ConvBlock(filters[2] + filters[3], filters[2])\n",
    "        self.up2 = nn.ConvTranspose2d(filters[2], filters[1], kernel_size=2, stride=2)\n",
    "        self.decoder2 = ConvBlock(filters[1] + filters[2], filters[1])\n",
    "        self.up3 = nn.ConvTranspose2d(filters[1], filters[0], kernel_size=2, stride=2)\n",
    "        self.decoder3 = ConvBlock(filters[0] + filters[1], filters[0])\n",
    "        self.up4 = nn.ConvTranspose2d(filters[0], filters[0] // 2, kernel_size=2, stride=2)\n",
    "        self.decoder4 = ConvBlock(filters[0] // 2, filters[0])\n",
    "        self.segmentation_head = nn.Conv2d(filters[0], 1, kernel_size=1)\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters[3], 1),\n",
    "            nn.Sigmoid()  # Predict in range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool1(e1))\n",
    "        e3 = self.encoder3(self.pool2(e2))\n",
    "        e4 = self.encoder4(self.pool3(e3))\n",
    "        b = self.bottleneck(self.pool4(e4))\n",
    "\n",
    "        plane_logits = self.classifier(b)\n",
    "\n",
    "        d1 = self.up1(b)\n",
    "        d1 = self.decoder1(torch.cat([d1, e4], dim=1))\n",
    "        d2 = self.up2(d1)\n",
    "        d2 = self.decoder2(torch.cat([d2, e3], dim=1))\n",
    "        d3 = self.up3(d2)\n",
    "        d3 = self.decoder3(torch.cat([d3, e2], dim=1))\n",
    "        d4 = self.up4(d3)\n",
    "        d4 = self.decoder4(d4)\n",
    "        segmentation = self.segmentation_head(d4)\n",
    "\n",
    "        value = self.regressor(b)\n",
    "\n",
    "        return plane_logits, segmentation, value\n",
    "\n",
    "# Data augmentation utility\n",
    "class RandomAugment:\n",
    "    def __call__(self, image, mask):\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask = TF.hflip(mask)\n",
    "        if random.random() > 0.5:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            image = TF.rotate(image, angle)\n",
    "            mask = TF.rotate(mask, angle)\n",
    "        return image, mask\n",
    "\n",
    "class UltrasoundDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, csv_path, transform=None, augment=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform or T.Compose([T.Resize((224, 224)), T.ToTensor()])\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['image'])\n",
    "        mask_path = os.path.join(self.mask_dir, row['image'].replace('.jpg', '_mask.png'))\n",
    "\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        if self.augment:\n",
    "            image, mask = self.augment(image, mask)\n",
    "\n",
    "        image = self.transform(image)\n",
    "        mask = self.transform(mask)\n",
    "\n",
    "        label_map = {'head': 0, 'abdomen': 1, 'femur': 2}\n",
    "        label = torch.tensor(label_map[row['plane'].lower()], dtype=torch.long)\n",
    "        value = torch.tensor(row['value'], dtype=torch.float32)\n",
    "\n",
    "        return image, mask, label, value\n",
    "\n",
    "# Example training loop with loss breakdown\n",
    "model = TeacherNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "cls_loss = nn.CrossEntropyLoss()\n",
    "seg_loss = nn.BCEWithLogitsLoss()\n",
    "reg_loss = nn.MSELoss()\n",
    "\n",
    "train_dataset = UltrasoundDataset(\"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/images\", \"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/masks\", \"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/kamra_teacher_expanded.csv\", augment=RandomAugment())\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for img, mask, label, value in train_loader:\n",
    "        img, mask, label, value = img.to(device), mask.to(device), label.to(device), value.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out_cls, out_seg, out_val = model(img)\n",
    "\n",
    "        loss_c = cls_loss(out_cls, label)\n",
    "        loss_s = seg_loss(out_seg, mask)\n",
    "        loss_r = reg_loss(out_val.view(-1), value.view(-1))\n",
    "\n",
    "        loss = loss_c + loss_s + 0.01 * loss_r\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Total={loss.item():.2f} | Cls={loss_c.item():.2f} | Seg={loss_s.item():.2f} | Reg={loss_r.item():.2f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"teacher_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b007e04-c2e8-4480-afb4-7e6cf63d273f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
