{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52807885-0e6b-4dc5-a15f-3175f05bfa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total=1.67 | Cls=1.16 | Seg=0.51 | Reg=0.04\n",
      "Epoch 2: Total=1.11 | Cls=0.72 | Seg=0.39 | Reg=0.30\n",
      "Epoch 3: Total=2.03 | Cls=1.69 | Seg=0.34 | Reg=0.12\n",
      "Epoch 4: Total=0.91 | Cls=0.59 | Seg=0.32 | Reg=0.29\n",
      "Epoch 5: Total=2.09 | Cls=1.77 | Seg=0.31 | Reg=0.23\n",
      "Epoch 6: Total=1.71 | Cls=1.42 | Seg=0.28 | Reg=0.28\n",
      "Epoch 7: Total=0.79 | Cls=0.50 | Seg=0.28 | Reg=0.28\n",
      "Epoch 8: Total=0.75 | Cls=0.49 | Seg=0.26 | Reg=0.25\n",
      "Epoch 9: Total=2.13 | Cls=1.85 | Seg=0.28 | Reg=0.00\n",
      "Epoch 10: Total=1.77 | Cls=1.53 | Seg=0.24 | Reg=0.06\n",
      "Epoch 11: Total=0.71 | Cls=0.48 | Seg=0.23 | Reg=0.27\n",
      "Epoch 12: Total=0.61 | Cls=0.39 | Seg=0.22 | Reg=0.09\n",
      "Epoch 13: Total=2.11 | Cls=1.90 | Seg=0.21 | Reg=0.04\n",
      "Epoch 14: Total=0.67 | Cls=0.47 | Seg=0.20 | Reg=0.30\n",
      "Epoch 15: Total=0.60 | Cls=0.41 | Seg=0.19 | Reg=0.29\n",
      "Epoch 16: Total=1.69 | Cls=1.50 | Seg=0.18 | Reg=0.02\n",
      "Epoch 17: Total=1.54 | Cls=1.36 | Seg=0.18 | Reg=0.13\n",
      "Epoch 18: Total=1.60 | Cls=1.43 | Seg=0.17 | Reg=0.04\n",
      "Epoch 19: Total=1.53 | Cls=1.37 | Seg=0.16 | Reg=0.01\n",
      "Epoch 20: Total=0.66 | Cls=0.50 | Seg=0.16 | Reg=0.30\n",
      "Epoch 21: Total=1.63 | Cls=1.47 | Seg=0.15 | Reg=0.00\n",
      "Epoch 22: Total=2.25 | Cls=2.09 | Seg=0.15 | Reg=0.25\n",
      "Epoch 23: Total=0.53 | Cls=0.38 | Seg=0.15 | Reg=0.15\n",
      "Epoch 24: Total=0.57 | Cls=0.43 | Seg=0.13 | Reg=0.12\n",
      "Epoch 25: Total=0.56 | Cls=0.42 | Seg=0.14 | Reg=0.31\n",
      "Epoch 26: Total=2.21 | Cls=2.08 | Seg=0.13 | Reg=0.02\n",
      "Epoch 27: Total=0.51 | Cls=0.38 | Seg=0.13 | Reg=0.09\n",
      "Epoch 28: Total=2.26 | Cls=2.15 | Seg=0.11 | Reg=0.00\n",
      "Epoch 29: Total=0.62 | Cls=0.51 | Seg=0.12 | Reg=0.16\n",
      "Epoch 30: Total=0.48 | Cls=0.37 | Seg=0.11 | Reg=0.17\n",
      "Epoch 31: Total=0.48 | Cls=0.38 | Seg=0.10 | Reg=0.20\n",
      "Epoch 32: Total=2.19 | Cls=2.09 | Seg=0.10 | Reg=0.00\n",
      "Epoch 33: Total=0.61 | Cls=0.51 | Seg=0.10 | Reg=0.12\n",
      "Epoch 34: Total=0.44 | Cls=0.34 | Seg=0.10 | Reg=0.28\n",
      "Epoch 35: Total=0.46 | Cls=0.37 | Seg=0.09 | Reg=0.30\n",
      "Epoch 36: Total=0.42 | Cls=0.33 | Seg=0.09 | Reg=0.25\n",
      "Epoch 37: Total=0.44 | Cls=0.34 | Seg=0.09 | Reg=0.20\n",
      "Epoch 38: Total=1.55 | Cls=1.46 | Seg=0.08 | Reg=0.01\n",
      "Epoch 39: Total=0.42 | Cls=0.33 | Seg=0.08 | Reg=0.26\n",
      "Epoch 40: Total=0.38 | Cls=0.29 | Seg=0.09 | Reg=0.27\n",
      "Epoch 41: Total=1.65 | Cls=1.57 | Seg=0.08 | Reg=0.01\n",
      "Epoch 42: Total=2.14 | Cls=2.07 | Seg=0.07 | Reg=0.15\n",
      "Epoch 43: Total=0.54 | Cls=0.42 | Seg=0.12 | Reg=0.07\n",
      "Epoch 44: Total=0.46 | Cls=0.39 | Seg=0.07 | Reg=0.30\n",
      "Epoch 45: Total=0.45 | Cls=0.38 | Seg=0.07 | Reg=0.30\n",
      "Epoch 46: Total=0.36 | Cls=0.29 | Seg=0.07 | Reg=0.15\n",
      "Epoch 47: Total=2.04 | Cls=1.98 | Seg=0.06 | Reg=0.01\n",
      "Epoch 48: Total=0.50 | Cls=0.43 | Seg=0.06 | Reg=0.29\n",
      "Epoch 49: Total=1.88 | Cls=1.81 | Seg=0.07 | Reg=0.28\n",
      "Epoch 50: Total=0.42 | Cls=0.34 | Seg=0.09 | Reg=0.28\n",
      "Epoch 51: Total=0.52 | Cls=0.46 | Seg=0.06 | Reg=0.12\n",
      "Epoch 52: Total=0.34 | Cls=0.28 | Seg=0.06 | Reg=0.15\n",
      "Epoch 53: Total=0.41 | Cls=0.36 | Seg=0.05 | Reg=0.31\n",
      "Epoch 54: Total=0.57 | Cls=0.51 | Seg=0.06 | Reg=0.30\n",
      "Epoch 55: Total=1.83 | Cls=1.78 | Seg=0.06 | Reg=0.03\n",
      "Epoch 56: Total=0.55 | Cls=0.50 | Seg=0.05 | Reg=0.14\n",
      "Epoch 57: Total=1.57 | Cls=1.53 | Seg=0.05 | Reg=0.14\n",
      "Epoch 58: Total=0.40 | Cls=0.35 | Seg=0.05 | Reg=0.28\n",
      "Epoch 59: Total=0.41 | Cls=0.36 | Seg=0.05 | Reg=0.16\n",
      "Epoch 60: Total=1.74 | Cls=1.69 | Seg=0.05 | Reg=0.12\n",
      "Epoch 61: Total=0.38 | Cls=0.34 | Seg=0.04 | Reg=0.31\n",
      "Epoch 62: Total=0.39 | Cls=0.34 | Seg=0.05 | Reg=0.29\n",
      "Epoch 63: Total=0.35 | Cls=0.30 | Seg=0.05 | Reg=0.24\n",
      "Epoch 64: Total=1.68 | Cls=1.63 | Seg=0.05 | Reg=0.02\n",
      "Epoch 65: Total=2.20 | Cls=2.15 | Seg=0.04 | Reg=0.02\n",
      "Epoch 66: Total=1.61 | Cls=1.57 | Seg=0.05 | Reg=0.10\n",
      "Epoch 67: Total=0.54 | Cls=0.49 | Seg=0.04 | Reg=0.11\n",
      "Epoch 68: Total=0.53 | Cls=0.49 | Seg=0.04 | Reg=0.33\n",
      "Epoch 69: Total=0.51 | Cls=0.47 | Seg=0.04 | Reg=0.30\n",
      "Epoch 70: Total=1.60 | Cls=1.56 | Seg=0.04 | Reg=0.01\n",
      "Epoch 71: Total=0.41 | Cls=0.37 | Seg=0.04 | Reg=0.13\n",
      "Epoch 72: Total=1.77 | Cls=1.74 | Seg=0.04 | Reg=0.01\n",
      "Epoch 73: Total=0.47 | Cls=0.44 | Seg=0.03 | Reg=0.32\n",
      "Epoch 74: Total=2.30 | Cls=2.26 | Seg=0.04 | Reg=0.11\n",
      "Epoch 75: Total=0.35 | Cls=0.31 | Seg=0.04 | Reg=0.28\n"
     ]
    }
   ],
   "source": [
    "# Teacher Model: Multi-Task (Classification + Segmentation + Regression with Normalized Output)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_classes=3):\n",
    "        super(TeacherNet, self).__init__()\n",
    "        filters = [64, 128, 256, 512]\n",
    "\n",
    "        self.encoder1 = ConvBlock(in_channels, filters[0])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.encoder2 = ConvBlock(filters[0], filters[1])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.encoder3 = ConvBlock(filters[1], filters[2])\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.encoder4 = ConvBlock(filters[2], filters[3])\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = ConvBlock(filters[3], filters[3])\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters[3], 3)\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(filters[3], filters[2], kernel_size=2, stride=2)\n",
    "        self.decoder1 = ConvBlock(filters[2] + filters[3], filters[2])\n",
    "        self.up2 = nn.ConvTranspose2d(filters[2], filters[1], kernel_size=2, stride=2)\n",
    "        self.decoder2 = ConvBlock(filters[1] + filters[2], filters[1])\n",
    "        self.up3 = nn.ConvTranspose2d(filters[1], filters[0], kernel_size=2, stride=2)\n",
    "        self.decoder3 = ConvBlock(filters[0] + filters[1], filters[0])\n",
    "        self.up4 = nn.ConvTranspose2d(filters[0], filters[0] // 2, kernel_size=2, stride=2)\n",
    "        self.decoder4 = ConvBlock(filters[0] // 2, filters[0])\n",
    "        self.segmentation_head = nn.Conv2d(filters[0], 1, kernel_size=1)\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters[3], 1),\n",
    "            nn.Sigmoid()  # Predict in range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool1(e1))\n",
    "        e3 = self.encoder3(self.pool2(e2))\n",
    "        e4 = self.encoder4(self.pool3(e3))\n",
    "        b = self.bottleneck(self.pool4(e4))\n",
    "\n",
    "        plane_logits = self.classifier(b)\n",
    "\n",
    "        d1 = self.up1(b)\n",
    "        d1 = self.decoder1(torch.cat([d1, e4], dim=1))\n",
    "        d2 = self.up2(d1)\n",
    "        d2 = self.decoder2(torch.cat([d2, e3], dim=1))\n",
    "        d3 = self.up3(d2)\n",
    "        d3 = self.decoder3(torch.cat([d3, e2], dim=1))\n",
    "        d4 = self.up4(d3)\n",
    "        d4 = self.decoder4(d4)\n",
    "        segmentation = self.segmentation_head(d4)\n",
    "\n",
    "        value = self.regressor(b)\n",
    "\n",
    "        return plane_logits, segmentation, value\n",
    "\n",
    "# =========================\n",
    "# NORMALIZATION SCRIPT\n",
    "# =========================\n",
    "def normalize_and_save():\n",
    "    df = pd.read_csv(\"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/kamra_teacher_expanded.csv\")\n",
    "    min_vals = df.groupby(\"type\")[\"value\"].min()\n",
    "    max_vals = df.groupby(\"type\")[\"value\"].max()\n",
    "\n",
    "    def normalize(row):\n",
    "        min_val = min_vals[row[\"type\"]]\n",
    "        max_val = max_vals[row[\"type\"]]\n",
    "        return (row[\"value\"] - min_val) / (max_val - min_val)\n",
    "\n",
    "    df[\"value_norm\"] = df.apply(normalize, axis=1)\n",
    "    df.to_csv(\"kamra_measurements_normalized.csv\", index=False)\n",
    "\n",
    "    min_max_df = pd.DataFrame({\"min\": min_vals, \"max\": max_vals})\n",
    "    min_max_df.to_csv(\"biometric_min_max.csv\")\n",
    "\n",
    "# =========================\n",
    "# INFERENCE DENORMALIZATION\n",
    "# =========================\n",
    "def denormalize(value_norm, biom_type, min_max_path=\"biometric_min_max.csv\"):\n",
    "    min_max = pd.read_csv(min_max_path, index_col=0)\n",
    "    row = min_max.loc[biom_type]\n",
    "    return value_norm * (row[\"max\"] - row[\"min\"]) + row[\"min\"]\n",
    "\n",
    "# =========================\n",
    "# DataLoader and Training Loop\n",
    "# =========================\n",
    "class RandomAugment:\n",
    "    def __call__(self, image, mask):\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask = TF.hflip(mask)\n",
    "        if random.random() > 0.5:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            image = TF.rotate(image, angle)\n",
    "            mask = TF.rotate(mask, angle)\n",
    "        return image, mask\n",
    "\n",
    "class UltrasoundDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, csv_path, transform=None, augment=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform or T.Compose([T.Resize((224, 224)), T.ToTensor()])\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['image'])\n",
    "        mask_path = os.path.join(self.mask_dir, row['image'].replace('.jpg', '_mask.png'))\n",
    "\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        if self.augment:\n",
    "            image, mask = self.augment(image, mask)\n",
    "\n",
    "        image = self.transform(image)\n",
    "        mask = self.transform(mask)\n",
    "\n",
    "        label_map = {'head': 0, 'abdomen': 1, 'femur': 2}\n",
    "        label = torch.tensor(label_map[row['plane'].lower()], dtype=torch.long)\n",
    "        value = torch.tensor(row['value_norm'], dtype=torch.float32)\n",
    "\n",
    "        return image, mask, label, value\n",
    "\n",
    "# Run normalization once before training\n",
    "normalize_and_save()\n",
    "\n",
    "model = TeacherNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "cls_loss = nn.CrossEntropyLoss()\n",
    "seg_loss = nn.BCEWithLogitsLoss()\n",
    "reg_loss = nn.MSELoss()\n",
    "\n",
    "train_dataset = UltrasoundDataset(\n",
    "    \"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/images\",\n",
    "    \"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/masks\",\n",
    "    \"kamra_measurements_normalized.csv\",\n",
    "    augment=RandomAugment()\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(75):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for img, mask, label, value in train_loader:\n",
    "        img, mask, label, value = img.to(device), mask.to(device), label.to(device), value.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out_cls, out_seg, out_val = model(img)\n",
    "\n",
    "        loss_c = cls_loss(out_cls, label)\n",
    "        loss_s = seg_loss(out_seg, mask)\n",
    "        loss_r = reg_loss(out_val.view(-1), value.view(-1))\n",
    "\n",
    "        loss = loss_c + loss_s + 0.01 * loss_r\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Total={loss.item():.2f} | Cls={loss_c.item():.2f} | Seg={loss_s.item():.2f} | Reg={loss_r.item():.2f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"teacher_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4c003-2c09-4457-b181-3a9f6617df74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
