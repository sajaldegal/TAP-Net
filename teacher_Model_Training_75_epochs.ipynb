{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9f795dd-9ccd-4bfa-8e56-9966dafd1529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total=1.79 | Cls=0.77 | Seg=0.47 | Reg=54.55\n",
      "Epoch 2: Total=10.18 | Cls=0.63 | Seg=0.37 | Reg=918.00\n",
      "Epoch 3: Total=1.36 | Cls=0.58 | Seg=0.43 | Reg=35.53\n",
      "Epoch 4: Total=2.35 | Cls=1.87 | Seg=0.32 | Reg=15.79\n",
      "Epoch 5: Total=1.10 | Cls=0.52 | Seg=0.33 | Reg=24.44\n",
      "Epoch 6: Total=52.08 | Cls=0.51 | Seg=0.29 | Reg=5127.47\n",
      "Epoch 7: Total=5.71 | Cls=1.42 | Seg=0.32 | Reg=397.72\n",
      "Epoch 8: Total=8.64 | Cls=0.47 | Seg=0.28 | Reg=789.76\n",
      "Epoch 9: Total=0.81 | Cls=0.47 | Seg=0.27 | Reg=7.31\n",
      "Epoch 10: Total=4.00 | Cls=1.42 | Seg=0.24 | Reg=233.84\n",
      "Epoch 11: Total=1.12 | Cls=0.52 | Seg=0.23 | Reg=36.37\n",
      "Epoch 12: Total=4.67 | Cls=1.37 | Seg=0.23 | Reg=306.54\n",
      "Epoch 13: Total=7.05 | Cls=0.54 | Seg=0.22 | Reg=629.13\n",
      "Epoch 14: Total=1.28 | Cls=0.52 | Seg=0.20 | Reg=55.60\n",
      "Epoch 15: Total=2.12 | Cls=1.91 | Seg=0.20 | Reg=1.19\n",
      "Epoch 16: Total=1.45 | Cls=0.53 | Seg=0.19 | Reg=72.90\n",
      "Epoch 17: Total=5.20 | Cls=0.49 | Seg=0.19 | Reg=452.70\n",
      "Epoch 18: Total=2.11 | Cls=1.89 | Seg=0.18 | Reg=3.59\n",
      "Epoch 19: Total=1.66 | Cls=0.55 | Seg=0.18 | Reg=93.14\n",
      "Epoch 20: Total=2.20 | Cls=1.88 | Seg=0.16 | Reg=15.20\n",
      "Epoch 21: Total=51.47 | Cls=0.53 | Seg=0.15 | Reg=5078.27\n",
      "Epoch 22: Total=0.75 | Cls=0.48 | Seg=0.15 | Reg=11.38\n",
      "Epoch 23: Total=2.36 | Cls=1.90 | Seg=0.15 | Reg=31.35\n",
      "Epoch 24: Total=42.71 | Cls=0.52 | Seg=0.14 | Reg=4204.44\n",
      "Epoch 25: Total=0.74 | Cls=0.47 | Seg=0.14 | Reg=13.01\n",
      "Epoch 26: Total=4.31 | Cls=1.46 | Seg=0.15 | Reg=270.91\n",
      "Epoch 27: Total=2.66 | Cls=1.95 | Seg=0.13 | Reg=58.85\n",
      "Epoch 28: Total=2.33 | Cls=0.54 | Seg=0.14 | Reg=164.62\n",
      "Epoch 29: Total=2.87 | Cls=1.47 | Seg=0.12 | Reg=128.30\n",
      "Epoch 30: Total=1.16 | Cls=0.47 | Seg=0.14 | Reg=55.77\n",
      "Epoch 31: Total=2.88 | Cls=1.94 | Seg=0.12 | Reg=83.01\n",
      "Epoch 32: Total=1.39 | Cls=0.53 | Seg=0.12 | Reg=74.88\n",
      "Epoch 33: Total=2.97 | Cls=1.94 | Seg=0.11 | Reg=93.09\n",
      "Epoch 34: Total=1.54 | Cls=0.47 | Seg=0.16 | Reg=89.90\n",
      "Epoch 35: Total=1.75 | Cls=0.48 | Seg=0.16 | Reg=111.09\n",
      "Epoch 36: Total=48.28 | Cls=0.48 | Seg=0.10 | Reg=4770.34\n",
      "Epoch 37: Total=3.90 | Cls=0.48 | Seg=0.09 | Reg=333.50\n",
      "Epoch 38: Total=3.24 | Cls=1.89 | Seg=0.09 | Reg=125.88\n",
      "Epoch 39: Total=3.21 | Cls=1.80 | Seg=0.11 | Reg=130.03\n",
      "Epoch 40: Total=3.34 | Cls=1.67 | Seg=0.08 | Reg=159.12\n",
      "Epoch 41: Total=3.37 | Cls=1.70 | Seg=0.09 | Reg=158.50\n",
      "Epoch 42: Total=35.12 | Cls=0.56 | Seg=0.08 | Reg=3447.44\n",
      "Epoch 43: Total=4.47 | Cls=0.50 | Seg=0.08 | Reg=388.86\n",
      "Epoch 44: Total=3.77 | Cls=1.85 | Seg=0.08 | Reg=184.23\n",
      "Epoch 45: Total=5.44 | Cls=1.56 | Seg=0.08 | Reg=379.24\n",
      "Epoch 46: Total=27.26 | Cls=0.55 | Seg=0.07 | Reg=2664.50\n",
      "Epoch 47: Total=5.61 | Cls=1.47 | Seg=0.07 | Reg=407.47\n",
      "Epoch 48: Total=4.99 | Cls=0.49 | Seg=0.07 | Reg=443.27\n",
      "Epoch 49: Total=5.82 | Cls=1.60 | Seg=0.08 | Reg=413.35\n",
      "Epoch 50: Total=1.43 | Cls=1.36 | Seg=0.07 | Reg=0.00\n",
      "Epoch 51: Total=5.28 | Cls=0.55 | Seg=0.07 | Reg=466.46\n",
      "Epoch 52: Total=1.63 | Cls=0.47 | Seg=0.08 | Reg=108.50\n",
      "Epoch 53: Total=5.59 | Cls=0.45 | Seg=0.07 | Reg=506.98\n",
      "Epoch 54: Total=4.92 | Cls=1.92 | Seg=0.06 | Reg=293.79\n",
      "Epoch 55: Total=4.82 | Cls=1.80 | Seg=0.06 | Reg=296.51\n",
      "Epoch 56: Total=5.49 | Cls=0.57 | Seg=0.06 | Reg=486.31\n",
      "Epoch 57: Total=2.62 | Cls=0.46 | Seg=0.06 | Reg=210.23\n",
      "Epoch 58: Total=4.59 | Cls=1.98 | Seg=0.05 | Reg=255.96\n",
      "Epoch 59: Total=4.35 | Cls=1.77 | Seg=0.05 | Reg=252.08\n",
      "Epoch 60: Total=1.32 | Cls=0.50 | Seg=0.06 | Reg=76.67\n",
      "Epoch 61: Total=1.91 | Cls=1.39 | Seg=0.05 | Reg=47.39\n",
      "Epoch 62: Total=4.73 | Cls=1.85 | Seg=0.05 | Reg=282.70\n",
      "Epoch 63: Total=37.37 | Cls=0.57 | Seg=0.04 | Reg=3675.56\n",
      "Epoch 64: Total=1.18 | Cls=0.45 | Seg=0.05 | Reg=68.22\n",
      "Epoch 65: Total=37.78 | Cls=0.41 | Seg=0.05 | Reg=3732.09\n",
      "Epoch 66: Total=35.64 | Cls=0.42 | Seg=0.05 | Reg=3517.16\n",
      "Epoch 67: Total=1.84 | Cls=1.74 | Seg=0.05 | Reg=5.08\n",
      "Epoch 68: Total=1.65 | Cls=1.56 | Seg=0.05 | Reg=3.77\n",
      "Epoch 69: Total=5.52 | Cls=1.90 | Seg=0.05 | Reg=357.99\n",
      "Epoch 70: Total=5.41 | Cls=1.78 | Seg=0.04 | Reg=358.05\n",
      "Epoch 71: Total=30.51 | Cls=0.51 | Seg=0.04 | Reg=2995.37\n",
      "Epoch 72: Total=30.51 | Cls=0.47 | Seg=0.05 | Reg=2999.60\n",
      "Epoch 73: Total=6.47 | Cls=0.48 | Seg=0.04 | Reg=595.10\n",
      "Epoch 74: Total=3.09 | Cls=0.41 | Seg=0.04 | Reg=263.91\n",
      "Epoch 75: Total=35.10 | Cls=0.45 | Seg=0.04 | Reg=3461.09\n"
     ]
    }
   ],
   "source": [
    "# Teacher Model: Multi-Task (Classification + Segmentation + Regression)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_classes=3):\n",
    "        super(TeacherNet, self).__init__()\n",
    "        filters = [64, 128, 256, 512]\n",
    "\n",
    "        self.encoder1 = ConvBlock(in_channels, filters[0])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.encoder2 = ConvBlock(filters[0], filters[1])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.encoder3 = ConvBlock(filters[1], filters[2])\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.encoder4 = ConvBlock(filters[2], filters[3])\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = ConvBlock(filters[3], filters[3])\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters[3], 3)\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(filters[3], filters[2], kernel_size=2, stride=2)\n",
    "        self.decoder1 = ConvBlock(filters[2] + filters[3], filters[2])\n",
    "        self.up2 = nn.ConvTranspose2d(filters[2], filters[1], kernel_size=2, stride=2)\n",
    "        self.decoder2 = ConvBlock(filters[1] + filters[2], filters[1])\n",
    "        self.up3 = nn.ConvTranspose2d(filters[1], filters[0], kernel_size=2, stride=2)\n",
    "        self.decoder3 = ConvBlock(filters[0] + filters[1], filters[0])\n",
    "        self.up4 = nn.ConvTranspose2d(filters[0], filters[0] // 2, kernel_size=2, stride=2)\n",
    "        self.decoder4 = ConvBlock(filters[0] // 2, filters[0])\n",
    "        self.segmentation_head = nn.Conv2d(filters[0], 1, kernel_size=1)\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters[3], 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool1(e1))\n",
    "        e3 = self.encoder3(self.pool2(e2))\n",
    "        e4 = self.encoder4(self.pool3(e3))\n",
    "        b = self.bottleneck(self.pool4(e4))\n",
    "\n",
    "        plane_logits = self.classifier(b)\n",
    "\n",
    "        d1 = self.up1(b)\n",
    "        d1 = self.decoder1(torch.cat([d1, e4], dim=1))\n",
    "        d2 = self.up2(d1)\n",
    "        d2 = self.decoder2(torch.cat([d2, e3], dim=1))\n",
    "        d3 = self.up3(d2)\n",
    "        d3 = self.decoder3(torch.cat([d3, e2], dim=1))\n",
    "        d4 = self.up4(d3)\n",
    "        d4 = self.decoder4(d4)\n",
    "        segmentation = self.segmentation_head(d4)\n",
    "\n",
    "        value = self.regressor(b)\n",
    "\n",
    "        return plane_logits, segmentation, value\n",
    "\n",
    "# Data augmentation utility\n",
    "class RandomAugment:\n",
    "    def __call__(self, image, mask):\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask = TF.hflip(mask)\n",
    "        if random.random() > 0.5:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            image = TF.rotate(image, angle)\n",
    "            mask = TF.rotate(mask, angle)\n",
    "        return image, mask\n",
    "\n",
    "class UltrasoundDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, csv_path, transform=None, augment=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform or T.Compose([T.Resize((224, 224)), T.ToTensor()])\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['image'])\n",
    "        mask_path = os.path.join(self.mask_dir, row['image'].replace('.jpg', '_mask.png'))\n",
    "\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        if self.augment:\n",
    "            image, mask = self.augment(image, mask)\n",
    "\n",
    "        image = self.transform(image)\n",
    "        mask = self.transform(mask)\n",
    "\n",
    "        label_map = {'head': 0, 'abdomen': 1, 'femur': 2}\n",
    "        label = torch.tensor(label_map[row['plane'].lower()], dtype=torch.long)\n",
    "        value = torch.tensor(row['value'], dtype=torch.float32)\n",
    "\n",
    "        return image, mask, label, value\n",
    "\n",
    "# Example training loop with loss breakdown\n",
    "model = TeacherNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "cls_loss = nn.CrossEntropyLoss()\n",
    "seg_loss = nn.BCEWithLogitsLoss()\n",
    "reg_loss = nn.MSELoss()\n",
    "\n",
    "train_dataset = UltrasoundDataset(\"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/images\", \"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/masks\", \"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/kamra_teacher_expanded.csv\", augment=RandomAugment())\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(75):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for img, mask, label, value in train_loader:\n",
    "        img, mask, label, value = img.to(device), mask.to(device), label.to(device), value.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out_cls, out_seg, out_val = model(img)\n",
    "\n",
    "        loss_c = cls_loss(out_cls, label)\n",
    "        loss_s = seg_loss(out_seg, mask)\n",
    "        loss_r = reg_loss(out_val.view(-1), value.view(-1))\n",
    "\n",
    "        loss = loss_c + loss_s + 0.01 * loss_r\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Total={loss.item():.2f} | Cls={loss_c.item():.2f} | Seg={loss_s.item():.2f} | Reg={loss_r.item():.2f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"teacher_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b007e04-c2e8-4480-afb4-7e6cf63d273f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
