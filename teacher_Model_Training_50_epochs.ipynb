{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9f795dd-9ccd-4bfa-8e56-9966dafd1529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total=10.72 | Cls=1.22 | Seg=0.55 | Reg=895.39\n",
      "Epoch 2: Total=2.26 | Cls=1.71 | Seg=0.42 | Reg=13.96\n",
      "Epoch 3: Total=1.45 | Cls=0.60 | Seg=0.39 | Reg=46.74\n",
      "Epoch 4: Total=5.30 | Cls=1.38 | Seg=0.37 | Reg=354.55\n",
      "Epoch 5: Total=9.51 | Cls=1.34 | Seg=0.33 | Reg=784.58\n",
      "Epoch 6: Total=2.36 | Cls=1.94 | Seg=0.30 | Reg=11.79\n",
      "Epoch 7: Total=61.67 | Cls=0.56 | Seg=0.29 | Reg=6082.59\n",
      "Epoch 8: Total=56.51 | Cls=0.50 | Seg=0.28 | Reg=5572.55\n",
      "Epoch 9: Total=62.06 | Cls=0.48 | Seg=0.26 | Reg=6131.50\n",
      "Epoch 10: Total=0.98 | Cls=0.45 | Seg=0.26 | Reg=27.29\n",
      "Epoch 11: Total=59.02 | Cls=0.45 | Seg=0.29 | Reg=5828.29\n",
      "Epoch 12: Total=0.75 | Cls=0.43 | Seg=0.25 | Reg=7.44\n",
      "Epoch 13: Total=8.60 | Cls=1.50 | Seg=0.22 | Reg=687.23\n",
      "Epoch 14: Total=5.82 | Cls=1.45 | Seg=0.22 | Reg=415.67\n",
      "Epoch 15: Total=2.20 | Cls=1.94 | Seg=0.21 | Reg=4.48\n",
      "Epoch 16: Total=2.26 | Cls=1.52 | Seg=0.29 | Reg=45.31\n",
      "Epoch 17: Total=5.46 | Cls=1.34 | Seg=0.24 | Reg=388.33\n",
      "Epoch 18: Total=1.49 | Cls=0.53 | Seg=0.19 | Reg=77.94\n",
      "Epoch 19: Total=54.80 | Cls=0.48 | Seg=0.18 | Reg=5414.18\n",
      "Epoch 20: Total=2.23 | Cls=1.96 | Seg=0.21 | Reg=5.65\n",
      "Epoch 21: Total=0.69 | Cls=0.47 | Seg=0.17 | Reg=4.24\n",
      "Epoch 22: Total=3.29 | Cls=0.42 | Seg=0.22 | Reg=265.29\n",
      "Epoch 23: Total=4.41 | Cls=1.53 | Seg=0.18 | Reg=270.98\n",
      "Epoch 24: Total=2.04 | Cls=0.49 | Seg=0.16 | Reg=138.48\n",
      "Epoch 25: Total=2.75 | Cls=1.51 | Seg=0.16 | Reg=107.67\n",
      "Epoch 26: Total=2.30 | Cls=0.50 | Seg=0.14 | Reg=165.47\n",
      "Epoch 27: Total=4.95 | Cls=0.48 | Seg=0.14 | Reg=432.48\n",
      "Epoch 28: Total=2.45 | Cls=0.47 | Seg=0.14 | Reg=183.56\n",
      "Epoch 29: Total=2.52 | Cls=0.44 | Seg=0.13 | Reg=195.59\n",
      "Epoch 30: Total=0.98 | Cls=0.49 | Seg=0.13 | Reg=35.66\n",
      "Epoch 31: Total=2.38 | Cls=1.68 | Seg=0.12 | Reg=57.07\n",
      "Epoch 32: Total=2.95 | Cls=0.51 | Seg=0.12 | Reg=231.84\n",
      "Epoch 33: Total=47.54 | Cls=0.48 | Seg=0.12 | Reg=4694.49\n",
      "Epoch 34: Total=3.89 | Cls=1.42 | Seg=0.12 | Reg=234.63\n",
      "Epoch 35: Total=2.61 | Cls=0.52 | Seg=0.11 | Reg=197.50\n",
      "Epoch 36: Total=1.54 | Cls=0.49 | Seg=0.15 | Reg=89.97\n",
      "Epoch 37: Total=3.57 | Cls=0.50 | Seg=0.11 | Reg=297.18\n",
      "Epoch 38: Total=3.79 | Cls=0.43 | Seg=0.10 | Reg=325.31\n",
      "Epoch 39: Total=1.83 | Cls=0.45 | Seg=0.10 | Reg=127.97\n",
      "Epoch 40: Total=2.74 | Cls=1.48 | Seg=0.09 | Reg=116.67\n",
      "Epoch 41: Total=36.96 | Cls=0.49 | Seg=0.09 | Reg=3637.71\n",
      "Epoch 42: Total=1.22 | Cls=0.40 | Seg=0.12 | Reg=70.05\n",
      "Epoch 43: Total=3.78 | Cls=2.01 | Seg=0.09 | Reg=168.51\n",
      "Epoch 44: Total=34.09 | Cls=0.58 | Seg=0.09 | Reg=3341.87\n",
      "Epoch 45: Total=4.65 | Cls=0.49 | Seg=0.09 | Reg=407.30\n",
      "Epoch 46: Total=2.06 | Cls=0.45 | Seg=0.09 | Reg=151.52\n",
      "Epoch 47: Total=1.51 | Cls=1.42 | Seg=0.08 | Reg=0.91\n",
      "Epoch 48: Total=1.50 | Cls=1.41 | Seg=0.08 | Reg=0.74\n",
      "Epoch 49: Total=1.64 | Cls=1.31 | Seg=0.08 | Reg=25.25\n",
      "Epoch 50: Total=1.49 | Cls=1.40 | Seg=0.07 | Reg=2.13\n"
     ]
    }
   ],
   "source": [
    "# Teacher Model: Multi-Task (Classification + Segmentation + Regression)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class TeacherNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_classes=3):\n",
    "        super(TeacherNet, self).__init__()\n",
    "        filters = [64, 128, 256, 512]\n",
    "\n",
    "        self.encoder1 = ConvBlock(in_channels, filters[0])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.encoder2 = ConvBlock(filters[0], filters[1])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.encoder3 = ConvBlock(filters[1], filters[2])\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.encoder4 = ConvBlock(filters[2], filters[3])\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = ConvBlock(filters[3], filters[3])\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters[3], 3)\n",
    "        )\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(filters[3], filters[2], kernel_size=2, stride=2)\n",
    "        self.decoder1 = ConvBlock(filters[2] + filters[3], filters[2])\n",
    "        self.up2 = nn.ConvTranspose2d(filters[2], filters[1], kernel_size=2, stride=2)\n",
    "        self.decoder2 = ConvBlock(filters[1] + filters[2], filters[1])\n",
    "        self.up3 = nn.ConvTranspose2d(filters[1], filters[0], kernel_size=2, stride=2)\n",
    "        self.decoder3 = ConvBlock(filters[0] + filters[1], filters[0])\n",
    "        self.up4 = nn.ConvTranspose2d(filters[0], filters[0] // 2, kernel_size=2, stride=2)\n",
    "        self.decoder4 = ConvBlock(filters[0] // 2, filters[0])\n",
    "        self.segmentation_head = nn.Conv2d(filters[0], 1, kernel_size=1)\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters[3], 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool1(e1))\n",
    "        e3 = self.encoder3(self.pool2(e2))\n",
    "        e4 = self.encoder4(self.pool3(e3))\n",
    "        b = self.bottleneck(self.pool4(e4))\n",
    "\n",
    "        plane_logits = self.classifier(b)\n",
    "\n",
    "        d1 = self.up1(b)\n",
    "        d1 = self.decoder1(torch.cat([d1, e4], dim=1))\n",
    "        d2 = self.up2(d1)\n",
    "        d2 = self.decoder2(torch.cat([d2, e3], dim=1))\n",
    "        d3 = self.up3(d2)\n",
    "        d3 = self.decoder3(torch.cat([d3, e2], dim=1))\n",
    "        d4 = self.up4(d3)\n",
    "        d4 = self.decoder4(d4)\n",
    "        segmentation = self.segmentation_head(d4)\n",
    "\n",
    "        value = self.regressor(b)\n",
    "\n",
    "        return plane_logits, segmentation, value\n",
    "\n",
    "# Data augmentation utility\n",
    "class RandomAugment:\n",
    "    def __call__(self, image, mask):\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask = TF.hflip(mask)\n",
    "        if random.random() > 0.5:\n",
    "            angle = random.uniform(-15, 15)\n",
    "            image = TF.rotate(image, angle)\n",
    "            mask = TF.rotate(mask, angle)\n",
    "        return image, mask\n",
    "\n",
    "class UltrasoundDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, csv_path, transform=None, augment=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.transform = transform or T.Compose([T.Resize((224, 224)), T.ToTensor()])\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_path = os.path.join(self.image_dir, row['image'])\n",
    "        mask_path = os.path.join(self.mask_dir, row['image'].replace('.jpg', '_mask.png'))\n",
    "\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        if self.augment:\n",
    "            image, mask = self.augment(image, mask)\n",
    "\n",
    "        image = self.transform(image)\n",
    "        mask = self.transform(mask)\n",
    "\n",
    "        label_map = {'head': 0, 'abdomen': 1, 'femur': 2}\n",
    "        label = torch.tensor(label_map[row['plane'].lower()], dtype=torch.long)\n",
    "        value = torch.tensor(row['value'], dtype=torch.float32)\n",
    "\n",
    "        return image, mask, label, value\n",
    "\n",
    "# Example training loop with loss breakdown\n",
    "model = TeacherNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "cls_loss = nn.CrossEntropyLoss()\n",
    "seg_loss = nn.BCEWithLogitsLoss()\n",
    "reg_loss = nn.MSELoss()\n",
    "\n",
    "train_dataset = UltrasoundDataset(\"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/images\", \"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/masks\", \"G:/Sajal_Data/Obj_4_Code/Teacher_model_training/data/kamra_teacher_expanded.csv\", augment=RandomAugment())\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for img, mask, label, value in train_loader:\n",
    "        img, mask, label, value = img.to(device), mask.to(device), label.to(device), value.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out_cls, out_seg, out_val = model(img)\n",
    "\n",
    "        loss_c = cls_loss(out_cls, label)\n",
    "        loss_s = seg_loss(out_seg, mask)\n",
    "        loss_r = reg_loss(out_val.view(-1), value.view(-1))\n",
    "\n",
    "        loss = loss_c + loss_s + 0.01 * loss_r\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Total={loss.item():.2f} | Cls={loss_c.item():.2f} | Seg={loss_s.item():.2f} | Reg={loss_r.item():.2f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"teacher_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b007e04-c2e8-4480-afb4-7e6cf63d273f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
